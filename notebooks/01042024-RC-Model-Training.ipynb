{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from src.training import baseline, lasso, random_forest, ridge, svr\n",
    "\n",
    "baseline.baseline(X_train, y_train)\n",
    "lasso.lasso(X_train, y_train)\n",
    "random_forest.random_forest(X_train, y_train.values.ravel())\n",
    "ridge.ridge(X_train, y_train)\n",
    "svr.svr(X_train, y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import random_forest\n",
    "random_forest.random_forest(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../conf/models/' + 'best_random_forest', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\randy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:604: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from src.training import ensemble\n",
    "\n",
    "ensemble.ensemble(['best_random_forest', 'best_lasso', 'best_ridge'], X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline model: \n",
      "\n",
      "Mean Absolute Error (MAE): 4.79\n",
      "Mean Squared Error (MSE): 68.10\n",
      "Score:0.4175210760138829\n",
      "\n",
      "\n",
      "best_lasso model: \n",
      "\n",
      "Mean Absolute Error (MAE): 4.78\n",
      "Mean Squared Error (MSE): 67.97\n",
      "Score:0.41861227779751753\n",
      "\n",
      "\n",
      "best_random_forest model: \n",
      "\n",
      "Mean Absolute Error (MAE): 3.48\n",
      "Mean Squared Error (MSE): 27.93\n",
      "Score:0.7611091192993388\n",
      "\n",
      "\n",
      "best_ridge model: \n",
      "\n",
      "Mean Absolute Error (MAE): 4.78\n",
      "Mean Squared Error (MSE): 69.03\n",
      "Score:0.40951437522588896\n",
      "\n",
      "\n",
      "best_svr model: \n",
      "\n",
      "Mean Absolute Error (MAE): 11.59\n",
      "Mean Squared Error (MSE): 275.67\n",
      "Score:-1.357904803858578\n",
      "\n",
      "\n",
      "ensemble model: \n",
      "\n",
      "Mean Absolute Error (MAE): 4.12\n",
      "Mean Squared Error (MSE): 48.42\n",
      "Score:0.5858605831151669\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation import results\n",
    "\n",
    "results.results(\"../conf/models\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\randy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\randy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\randy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 25)                175       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 284 (1.11 KB)\n",
      "Trainable params: 284 (1.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From c:\\Users\\randy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\randy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 1s 15ms/step - loss: 91.4526 - r2_score: -0.9454 - val_loss: 94.1395 - val_r2_score: -1.4101\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 88.5769 - r2_score: -0.8843 - val_loss: 91.3366 - val_r2_score: -1.3383\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 85.9631 - r2_score: -0.8287 - val_loss: 88.5472 - val_r2_score: -1.2669\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 83.2211 - r2_score: -0.7703 - val_loss: 85.7415 - val_r2_score: -1.1951\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 80.5659 - r2_score: -0.7138 - val_loss: 82.7394 - val_r2_score: -1.1182\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 77.7613 - r2_score: -0.6542 - val_loss: 79.6628 - val_r2_score: -1.0395\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 74.8393 - r2_score: -0.5920 - val_loss: 76.4435 - val_r2_score: -0.9571\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 71.6954 - r2_score: -0.5251 - val_loss: 73.1815 - val_r2_score: -0.8736\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 68.6451 - r2_score: -0.4603 - val_loss: 69.5633 - val_r2_score: -0.7809\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 65.2394 - r2_score: -0.3878 - val_loss: 65.8777 - val_r2_score: -0.6866\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 61.7000 - r2_score: -0.3125 - val_loss: 62.1851 - val_r2_score: -0.5920\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 58.2599 - r2_score: -0.2393 - val_loss: 58.1922 - val_r2_score: -0.4898\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 54.5600 - r2_score: -0.1606 - val_loss: 54.4159 - val_r2_score: -0.3931\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 51.1141 - r2_score: -0.0873 - val_loss: 50.6078 - val_r2_score: -0.2956\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 47.5832 - r2_score: -0.0122 - val_loss: 47.1260 - val_r2_score: -0.2065\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.7289 - r2_score: 0.0485 - val_loss: 43.5014 - val_r2_score: -0.1137\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 41.6878 - r2_score: 0.1132 - val_loss: 40.4377 - val_r2_score: -0.0353\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 39.0416 - r2_score: 0.1695 - val_loss: 37.8906 - val_r2_score: 0.0299\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 36.8476 - r2_score: 0.2162 - val_loss: 35.6956 - val_r2_score: 0.0861\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 35.0210 - r2_score: 0.2550 - val_loss: 33.7587 - val_r2_score: 0.1357\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 33.4181 - r2_score: 0.2891 - val_loss: 32.1626 - val_r2_score: 0.1766\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 32.0745 - r2_score: 0.3177 - val_loss: 30.8399 - val_r2_score: 0.2105\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 30.9982 - r2_score: 0.3406 - val_loss: 29.7093 - val_r2_score: 0.2394\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 30.1183 - r2_score: 0.3593 - val_loss: 28.6884 - val_r2_score: 0.2655\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 29.2775 - r2_score: 0.3772 - val_loss: 27.8119 - val_r2_score: 0.2880\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 28.5731 - r2_score: 0.3922 - val_loss: 27.0632 - val_r2_score: 0.3071\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 27.9643 - r2_score: 0.4051 - val_loss: 26.3151 - val_r2_score: 0.3263\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.3266 - r2_score: 0.4187 - val_loss: 25.6574 - val_r2_score: 0.3431\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 26.7846 - r2_score: 0.4302 - val_loss: 25.0290 - val_r2_score: 0.3592\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 26.2482 - r2_score: 0.4416 - val_loss: 24.4661 - val_r2_score: 0.3736\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 25.7695 - r2_score: 0.4518 - val_loss: 23.9419 - val_r2_score: 0.3871\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 25.3507 - r2_score: 0.4607 - val_loss: 23.4312 - val_r2_score: 0.4001\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 24.9322 - r2_score: 0.4696 - val_loss: 22.9711 - val_r2_score: 0.4119\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 24.5299 - r2_score: 0.4782 - val_loss: 22.4851 - val_r2_score: 0.4244\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 24.1652 - r2_score: 0.4859 - val_loss: 22.1043 - val_r2_score: 0.4341\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 23.7903 - r2_score: 0.4939 - val_loss: 21.7355 - val_r2_score: 0.4435\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 23.5448 - r2_score: 0.4991 - val_loss: 21.3640 - val_r2_score: 0.4531\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 23.1648 - r2_score: 0.5072 - val_loss: 21.0006 - val_r2_score: 0.4624\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.8331 - r2_score: 0.5143 - val_loss: 20.6711 - val_r2_score: 0.4708\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 22.5376 - r2_score: 0.5206 - val_loss: 20.3558 - val_r2_score: 0.4789\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 22.2708 - r2_score: 0.5262 - val_loss: 20.0249 - val_r2_score: 0.4873\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 22.0046 - r2_score: 0.5319 - val_loss: 19.7687 - val_r2_score: 0.4939\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 21.7564 - r2_score: 0.5372 - val_loss: 19.5132 - val_r2_score: 0.5004\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 21.5036 - r2_score: 0.5426 - val_loss: 19.2090 - val_r2_score: 0.5082\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 21.3021 - r2_score: 0.5469 - val_loss: 18.9492 - val_r2_score: 0.5149\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 21.0409 - r2_score: 0.5524 - val_loss: 18.7438 - val_r2_score: 0.5201\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 20.7966 - r2_score: 0.5576 - val_loss: 18.4859 - val_r2_score: 0.5267\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 20.5843 - r2_score: 0.5621 - val_loss: 18.1892 - val_r2_score: 0.5343\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 20.3461 - r2_score: 0.5672 - val_loss: 18.0021 - val_r2_score: 0.5391\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 20.1316 - r2_score: 0.5717 - val_loss: 17.7713 - val_r2_score: 0.5450\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 19.9130 - r2_score: 0.5764 - val_loss: 17.5697 - val_r2_score: 0.5502\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 19.7081 - r2_score: 0.5808 - val_loss: 17.3672 - val_r2_score: 0.5554\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 19.5617 - r2_score: 0.5839 - val_loss: 17.1751 - val_r2_score: 0.5603\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 19.3033 - r2_score: 0.5894 - val_loss: 16.9963 - val_r2_score: 0.5649\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 19.1058 - r2_score: 0.5936 - val_loss: 16.7939 - val_r2_score: 0.5701\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18.9287 - r2_score: 0.5973 - val_loss: 16.6372 - val_r2_score: 0.5741\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18.7350 - r2_score: 0.6015 - val_loss: 16.4505 - val_r2_score: 0.5788\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18.5725 - r2_score: 0.6049 - val_loss: 16.2760 - val_r2_score: 0.5833\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18.3752 - r2_score: 0.6091 - val_loss: 16.1116 - val_r2_score: 0.5875\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18.2079 - r2_score: 0.6127 - val_loss: 15.9350 - val_r2_score: 0.5920\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18.0316 - r2_score: 0.6164 - val_loss: 15.8285 - val_r2_score: 0.5948\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.9094 - r2_score: 0.6190 - val_loss: 15.6951 - val_r2_score: 0.5982\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.7142 - r2_score: 0.6232 - val_loss: 15.5265 - val_r2_score: 0.6025\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.5547 - r2_score: 0.6266 - val_loss: 15.3499 - val_r2_score: 0.6070\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.3942 - r2_score: 0.6300 - val_loss: 15.2624 - val_r2_score: 0.6093\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.2678 - r2_score: 0.6327 - val_loss: 15.1727 - val_r2_score: 0.6116\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 17.1006 - r2_score: 0.6362 - val_loss: 15.0210 - val_r2_score: 0.6154\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.9764 - r2_score: 0.6389 - val_loss: 14.9503 - val_r2_score: 0.6173\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.7949 - r2_score: 0.6427 - val_loss: 14.7969 - val_r2_score: 0.6212\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.7095 - r2_score: 0.6445 - val_loss: 14.6469 - val_r2_score: 0.6250\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.5460 - r2_score: 0.6480 - val_loss: 14.5501 - val_r2_score: 0.6275\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.4143 - r2_score: 0.6508 - val_loss: 14.4655 - val_r2_score: 0.6297\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.2878 - r2_score: 0.6535 - val_loss: 14.3370 - val_r2_score: 0.6330\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.2280 - r2_score: 0.6548 - val_loss: 14.2793 - val_r2_score: 0.6344\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 16.0940 - r2_score: 0.6576 - val_loss: 14.2589 - val_r2_score: 0.6350\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.9402 - r2_score: 0.6609 - val_loss: 14.1276 - val_r2_score: 0.6383\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.8458 - r2_score: 0.6629 - val_loss: 14.0637 - val_r2_score: 0.6399\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.7876 - r2_score: 0.6642 - val_loss: 14.0187 - val_r2_score: 0.6411\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.6284 - r2_score: 0.6675 - val_loss: 13.9448 - val_r2_score: 0.6430\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.5349 - r2_score: 0.6695 - val_loss: 13.8211 - val_r2_score: 0.6462\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.4600 - r2_score: 0.6711 - val_loss: 13.7158 - val_r2_score: 0.6489\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.3815 - r2_score: 0.6728 - val_loss: 13.7132 - val_r2_score: 0.6489\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.2582 - r2_score: 0.6754 - val_loss: 13.6453 - val_r2_score: 0.6507\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.1795 - r2_score: 0.6771 - val_loss: 13.5772 - val_r2_score: 0.6524\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.1148 - r2_score: 0.6785 - val_loss: 13.5262 - val_r2_score: 0.6537\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 15.0256 - r2_score: 0.6804 - val_loss: 13.4760 - val_r2_score: 0.6550\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.9576 - r2_score: 0.6818 - val_loss: 13.4168 - val_r2_score: 0.6565\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.8776 - r2_score: 0.6835 - val_loss: 13.3778 - val_r2_score: 0.6575\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.7989 - r2_score: 0.6852 - val_loss: 13.3531 - val_r2_score: 0.6581\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.6978 - r2_score: 0.6873 - val_loss: 13.3049 - val_r2_score: 0.6594\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.7128 - r2_score: 0.6870 - val_loss: 13.3080 - val_r2_score: 0.6593\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.5899 - r2_score: 0.6896 - val_loss: 13.1928 - val_r2_score: 0.6622\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.5214 - r2_score: 0.6911 - val_loss: 13.1452 - val_r2_score: 0.6635\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.4600 - r2_score: 0.6924 - val_loss: 13.0507 - val_r2_score: 0.6659\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.4465 - r2_score: 0.6927 - val_loss: 13.0657 - val_r2_score: 0.6655\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.3357 - r2_score: 0.6950 - val_loss: 13.0130 - val_r2_score: 0.6668\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.2668 - r2_score: 0.6965 - val_loss: 12.9442 - val_r2_score: 0.6686\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.2104 - r2_score: 0.6977 - val_loss: 12.9299 - val_r2_score: 0.6690\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.1610 - r2_score: 0.6988 - val_loss: 12.8541 - val_r2_score: 0.6709\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.0957 - r2_score: 0.7001 - val_loss: 12.8573 - val_r2_score: 0.6708\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 14.0473 - r2_score: 0.7012 - val_loss: 12.7987 - val_r2_score: 0.6723\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.9838 - r2_score: 0.7025 - val_loss: 12.7734 - val_r2_score: 0.6730\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.9906 - r2_score: 0.7024 - val_loss: 12.7221 - val_r2_score: 0.6743\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.8687 - r2_score: 0.7050 - val_loss: 12.7000 - val_r2_score: 0.6749\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.8099 - r2_score: 0.7062 - val_loss: 12.7219 - val_r2_score: 0.6743\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.7763 - r2_score: 0.7069 - val_loss: 12.6575 - val_r2_score: 0.6759\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.7086 - r2_score: 0.7084 - val_loss: 12.6577 - val_r2_score: 0.6759\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.6835 - r2_score: 0.7089 - val_loss: 12.6737 - val_r2_score: 0.6755\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.6175 - r2_score: 0.7103 - val_loss: 12.5765 - val_r2_score: 0.6780\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.5647 - r2_score: 0.7114 - val_loss: 12.5516 - val_r2_score: 0.6787\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.5122 - r2_score: 0.7126 - val_loss: 12.4888 - val_r2_score: 0.6803\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 13.4689 - r2_score: 0.7135 - val_loss: 12.4203 - val_r2_score: 0.6820\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.4199 - r2_score: 0.7145 - val_loss: 12.4200 - val_r2_score: 0.6820\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.3792 - r2_score: 0.7154 - val_loss: 12.3923 - val_r2_score: 0.6827\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.3416 - r2_score: 0.7162 - val_loss: 12.3615 - val_r2_score: 0.6835\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.2706 - r2_score: 0.7177 - val_loss: 12.3102 - val_r2_score: 0.6848\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.2626 - r2_score: 0.7179 - val_loss: 12.3053 - val_r2_score: 0.6850\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.1874 - r2_score: 0.7195 - val_loss: 12.2326 - val_r2_score: 0.6868\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.1434 - r2_score: 0.7204 - val_loss: 12.1985 - val_r2_score: 0.6877\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.1171 - r2_score: 0.7210 - val_loss: 12.1150 - val_r2_score: 0.6898\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.0908 - r2_score: 0.7215 - val_loss: 12.1547 - val_r2_score: 0.6888\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 13.0513 - r2_score: 0.7224 - val_loss: 12.1676 - val_r2_score: 0.6885\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.9911 - r2_score: 0.7236 - val_loss: 12.0713 - val_r2_score: 0.6910\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.9711 - r2_score: 0.7241 - val_loss: 11.9737 - val_r2_score: 0.6935\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.9355 - r2_score: 0.7248 - val_loss: 12.0691 - val_r2_score: 0.6910\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.8747 - r2_score: 0.7261 - val_loss: 12.1189 - val_r2_score: 0.6897\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.8475 - r2_score: 0.7267 - val_loss: 11.9457 - val_r2_score: 0.6942\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.7685 - r2_score: 0.7284 - val_loss: 11.9836 - val_r2_score: 0.6932\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.7377 - r2_score: 0.7290 - val_loss: 11.9464 - val_r2_score: 0.6942\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.7169 - r2_score: 0.7295 - val_loss: 11.8778 - val_r2_score: 0.6959\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.6569 - r2_score: 0.7308 - val_loss: 11.9140 - val_r2_score: 0.6950\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.6305 - r2_score: 0.7313 - val_loss: 11.9174 - val_r2_score: 0.6949\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 12.6242 - r2_score: 0.7315 - val_loss: 11.8546 - val_r2_score: 0.6965\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.5446 - r2_score: 0.7331 - val_loss: 11.8631 - val_r2_score: 0.6963\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.5306 - r2_score: 0.7334 - val_loss: 11.7765 - val_r2_score: 0.6985\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.4857 - r2_score: 0.7344 - val_loss: 11.7399 - val_r2_score: 0.6994\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.4612 - r2_score: 0.7349 - val_loss: 11.7199 - val_r2_score: 0.7000\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.4194 - r2_score: 0.7358 - val_loss: 11.6926 - val_r2_score: 0.7007\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.3938 - r2_score: 0.7364 - val_loss: 11.6542 - val_r2_score: 0.7016\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.3682 - r2_score: 0.7369 - val_loss: 11.7214 - val_r2_score: 0.6999\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.3105 - r2_score: 0.7381 - val_loss: 11.6979 - val_r2_score: 0.7005\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 12.2847 - r2_score: 0.7387 - val_loss: 11.6013 - val_r2_score: 0.7030\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.2601 - r2_score: 0.7392 - val_loss: 11.4850 - val_r2_score: 0.7060\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.1827 - r2_score: 0.7408 - val_loss: 11.5343 - val_r2_score: 0.7047\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.1493 - r2_score: 0.7416 - val_loss: 11.5531 - val_r2_score: 0.7042\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.1073 - r2_score: 0.7424 - val_loss: 11.5396 - val_r2_score: 0.7046\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.0946 - r2_score: 0.7427 - val_loss: 11.5103 - val_r2_score: 0.7053\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.0536 - r2_score: 0.7436 - val_loss: 11.4677 - val_r2_score: 0.7064\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 12.0200 - r2_score: 0.7443 - val_loss: 11.4750 - val_r2_score: 0.7062\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.9779 - r2_score: 0.7452 - val_loss: 11.4471 - val_r2_score: 0.7069\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.9492 - r2_score: 0.7458 - val_loss: 11.4299 - val_r2_score: 0.7074\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.9183 - r2_score: 0.7465 - val_loss: 11.4119 - val_r2_score: 0.7078\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.8845 - r2_score: 0.7472 - val_loss: 11.3745 - val_r2_score: 0.7088\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.8616 - r2_score: 0.7477 - val_loss: 11.4128 - val_r2_score: 0.7078\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.8138 - r2_score: 0.7487 - val_loss: 11.3889 - val_r2_score: 0.7084\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.7863 - r2_score: 0.7493 - val_loss: 11.3262 - val_r2_score: 0.7100\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.7526 - r2_score: 0.7500 - val_loss: 11.3480 - val_r2_score: 0.7095\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.7155 - r2_score: 0.7508 - val_loss: 11.2868 - val_r2_score: 0.7110\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.7169 - r2_score: 0.7508 - val_loss: 11.3336 - val_r2_score: 0.7098\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.6561 - r2_score: 0.7520 - val_loss: 11.2686 - val_r2_score: 0.7115\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.6492 - r2_score: 0.7522 - val_loss: 11.1685 - val_r2_score: 0.7141\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.5769 - r2_score: 0.7537 - val_loss: 11.1789 - val_r2_score: 0.7138\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.5533 - r2_score: 0.7542 - val_loss: 11.1969 - val_r2_score: 0.7133\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.5288 - r2_score: 0.7548 - val_loss: 11.1956 - val_r2_score: 0.7134\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.5389 - r2_score: 0.7545 - val_loss: 11.1859 - val_r2_score: 0.7136\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.4791 - r2_score: 0.7558 - val_loss: 11.1015 - val_r2_score: 0.7158\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.4337 - r2_score: 0.7568 - val_loss: 11.1880 - val_r2_score: 0.7136\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.3982 - r2_score: 0.7575 - val_loss: 11.1361 - val_r2_score: 0.7149\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.3563 - r2_score: 0.7584 - val_loss: 11.0856 - val_r2_score: 0.7162\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.3273 - r2_score: 0.7590 - val_loss: 11.1154 - val_r2_score: 0.7154\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.3296 - r2_score: 0.7590 - val_loss: 11.0729 - val_r2_score: 0.7165\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.2740 - r2_score: 0.7602 - val_loss: 11.0850 - val_r2_score: 0.7162\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.2524 - r2_score: 0.7606 - val_loss: 11.0347 - val_r2_score: 0.7175\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.2086 - r2_score: 0.7616 - val_loss: 11.0192 - val_r2_score: 0.7179\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 11.2067 - r2_score: 0.7616 - val_loss: 10.9859 - val_r2_score: 0.7187\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.1765 - r2_score: 0.7622 - val_loss: 10.9205 - val_r2_score: 0.7204\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.1310 - r2_score: 0.7632 - val_loss: 10.9919 - val_r2_score: 0.7186\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.1350 - r2_score: 0.7631 - val_loss: 10.9447 - val_r2_score: 0.7198\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.1117 - r2_score: 0.7636 - val_loss: 11.0229 - val_r2_score: 0.7178\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.0622 - r2_score: 0.7647 - val_loss: 10.9317 - val_r2_score: 0.7201\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.0492 - r2_score: 0.7650 - val_loss: 10.9676 - val_r2_score: 0.7192\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 11.0048 - r2_score: 0.7659 - val_loss: 10.9545 - val_r2_score: 0.7196\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.9804 - r2_score: 0.7664 - val_loss: 10.9773 - val_r2_score: 0.7190\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.9976 - r2_score: 0.7661 - val_loss: 10.8677 - val_r2_score: 0.7218\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.9534 - r2_score: 0.7670 - val_loss: 10.9260 - val_r2_score: 0.7203\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.9097 - r2_score: 0.7679 - val_loss: 10.8615 - val_r2_score: 0.7219\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.8688 - r2_score: 0.7688 - val_loss: 10.8623 - val_r2_score: 0.7219\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.8378 - r2_score: 0.7695 - val_loss: 10.8739 - val_r2_score: 0.7216\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.8512 - r2_score: 0.7692 - val_loss: 10.8623 - val_r2_score: 0.7219\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.8173 - r2_score: 0.7699 - val_loss: 10.8381 - val_r2_score: 0.7225\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.7694 - r2_score: 0.7709 - val_loss: 10.8372 - val_r2_score: 0.7226\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.7551 - r2_score: 0.7712 - val_loss: 10.7864 - val_r2_score: 0.7239\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.7534 - r2_score: 0.7712 - val_loss: 10.8572 - val_r2_score: 0.7220\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.7098 - r2_score: 0.7722 - val_loss: 10.7887 - val_r2_score: 0.7238\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.6699 - r2_score: 0.7730 - val_loss: 10.8000 - val_r2_score: 0.7235\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.6772 - r2_score: 0.7729 - val_loss: 10.8595 - val_r2_score: 0.7220\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.6253 - r2_score: 0.7740 - val_loss: 10.7729 - val_r2_score: 0.7242\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.5991 - r2_score: 0.7745 - val_loss: 10.7357 - val_r2_score: 0.7251\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.5952 - r2_score: 0.7746 - val_loss: 10.7583 - val_r2_score: 0.7246\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 10.5642 - r2_score: 0.7753 - val_loss: 10.7507 - val_r2_score: 0.7248\n"
     ]
    }
   ],
   "source": [
    "from src.training import neural\n",
    "\n",
    "neural.neural(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn model: \n",
      "\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 29.6289 - r2_score: 0.7466\n",
      "[29.62893295288086, 0.7465692758560181]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation import nnresults\n",
    "\n",
    "nnresults.nnresults(\"../conf/nnmodels\", X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
